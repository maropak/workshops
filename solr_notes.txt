1.
ConcurrentUpdateSolrClient - geared towards indexing-centric workloads. Buffers documents
internally before sending larger batches to Solr.
2.
robimy klaster na 2 nody na jednej maszynce
- by miec 2 osobne potrzebny zookeeper,
ale u nas dla mocka, wiec moze ok
3.
jak 2 nody to klekcja na 2 shards - rozproszone
- tyle samo replica ndexu, jak padnie to replica na drugim node 
4.
configSet, which at a minimum includes the two main configuration files for Solr:
the schema file (named either managed-schema or schema.xml), and solrconfig.xml.
- moze konieczne dla kazdej kolekcji definicja ? (jak niewielka/ograniczona ilosc), moze z UI i kombo ze zdefiniowanymi 
plene create
http://localhost:8983/solr/admin/collections?action=CREATE&name=techproducts&numShards=2&replicat
ionFactor=2&maxShardsPerNode=2&collection.configName=techproducts
!!!!!!! - SPR Z MAX SHARDS I 2KI
!!!! - SPR JAK CREATE ZE SCHEMA PODANA
5.
!!!!
- USTAWIENIE AUTOCOMMIT, po dodaniu kolekcji 
- nie trzeba na koncu commit robic
http://localhost:8983/solr/techproducts/config
{"set-property":{"updateHandler.autoSoftCommit.maxTime":"3000"}}
Successfully set-property updateHandler.autoSoftCommit.maxTime to
7.
zwraca 10 na strone, mozna ustawic na wiecej 
8.
mozna szukac po wszystkich polach, bez pole:val, tylko q=val
9.
- sort defult po ilosci wystapien, 
- mozna tez szukac po tych co nie maja danej wartosci
10.
- del
bin/solr delete -c techproducts
- create
bin/solr create -c <yourCollection> -s 2 -rf 2
- stop
bin/solr stop -all
10.
restart na 2 nody
./bin/solr start -c -p 8983 -s example/cloud/node1/solr
This starts the first node. When itâ€™s done start the second node, and tell it how to connect to to ZooKeeper:
./bin/solr start -c -p 7574 -s example/cloud/node2/solr -z localhost:9983
-- sciezki do root 
12.
w tym drugim pliku - solrconfig. xml wymaganym jest zdefiniowane fieldguessing, czyli co robic z polami co ich nie zna - field guessing
13.
facets
- dzieli wyniki na podane bloki, ilosc, range, grupy wg patternu
14.
standardowa apka to
- def schemy
- ladowani dokumentami
- dostarczenie wyszukiwania
17.
jak mam duzo danych, zapytan, duzy ruch,
to lepiej cloud na wielu serwerach 
(ewentualnie mozemy kilka instancji, badac obciazenie i podlaczac apke do moka z najmniejszym ???)
- ale lepiej w klastrze, rozdzial dokumentow na shards i merge, dzialania na replikacjach 
18.
przy starcie parametry jvm mozliwe 
-c - w cloud, mozna podac zookeeper zewnetrzy w skrypcie namiar , mozna przez -z
- mozna -m - memory, mozna to prze -X JVM
!19.
odpalenie na default :
bin/solr start -e cloud -noprompt
20.
-s - solr home, mozna podpac pod storege openshift
21.
!!!!!!!!!!!!!!!!
If you create another collection with bin/solr create -c contacts2, then another copy of the _default
directory will be uploaded to ZooKeeper under /configs/contacts2.
13.
jak uzyte default i chyba dla innych tez default jest dodawanie pol przez schemaless
14.
sciezka 
When you first install Solr, your home directory is server/solr. However, some examples may change this
location (such as, if you run bin/solr start -e cloud, your home directory will be example/cloud).
- w home 3many index !!!!!!!!!
15.
69-77

